# üåø Segmenta√ß√£o de Plantas Daninhas com DeepLabV3

Este projeto √© um pipeline completo de Deep Learning para **detectar e segmentar culturas (crops) e ervas daninhas (weeds)** usando o modelo DeepLabV3 em PyTorch.

O desafio central foi **converter anota√ß√µes de Bounding Box (YOLO)** em **M√°scaras de Segmenta√ß√£o**, preparando os dados para um modelo de segmenta√ß√£o sem√¢ntica.

---

## üéØ Resultado Final

O modelo aprende a classificar cada pixel da imagem em 3 categorias: **Fundo**, **Cultura** ou **Erva Daninha**.

| Imagem Original | M√°scara Real | M√°scara Prevista pelo Modelo |
| :---: | :---: | :---: |
| _ ![agri_0_975](https://github.com/user-attachments/assets/ef8f8037-ce2b-4cf2-a692-f456daaacab1)
 _ | _ <img width="512" height="512" alt="agri_0_975" src="https://github.com/user-attachments/assets/efba61be-a190-4169-8f9c-7290b01bfd7c" />
 _ | _ <img width="279" height="279" alt="image" src="https://github.com/user-attachments/assets/18f2df89-de94-4499-9a41-9f7727602839" />
_ |

---

## üöÄ O Pipeline (O que foi feito)

O *notebook* (`SegmentacaoDeepLabV3.ipynb`) executa o seguinte fluxo de trabalho:

1.  **üì• Download dos Dados:**
    * Baixa o dataset do Kaggle (que usa anota√ß√µes YOLO).

2.  **üî≥ ‚ûî üé® Convers√£o (BBox para M√°scara):**
    * L√™ os arquivos `.txt` (YOLO) e "desenha" m√°scaras `.png` preenchidas, convertendo ret√¢ngulos em segmenta√ß√£o pixel-a-pixel.

3.  **üóÇÔ∏è Organiza√ß√£o dos Dados:**
    * Divide os pares de Imagem/M√°scara em pastas `train/` e `val/`.

4.  **‚ú® Data Augmentation:**
    * Usa `albumentations` para aplicar transforma√ß√µes (Flips, Rota√ß√£o, etc.) de forma id√™ntica nas imagens e m√°scaras.

5.  **üß† Carregamento do Modelo (Transfer Learning):**
    * Carrega o `deeplabv3_resnet50` pr√©-treinado no COCO.
    * Substitui a camada final (de 21 classes) por uma nova camada para as nossas **3 classes**.

6.  **üèãÔ∏è Treinamento:**
    * Treina o modelo usando `CrossEntropyLoss` e salva o melhor checkpoint (`best_deeplab_model.pth`).

---

## üõ†Ô∏è Tecnologias Usadas

* **PyTorch** (para o modelo e treinamento)
* **Albumentations** (para Data Augmentation)
* **OpenCV** & **Pillow** (para manipula√ß√£o de imagens)
* **Scikit-learn** (para a divis√£o treino/valida√ß√£o)
* **Kaggle API** (para download dos dados)

---

## ‚ö° Como Executar

Este projeto √© feito para o **Google Colab**.

1.  **Depend√™ncias (`requirements.txt`):**
    * Este reposit√≥rio inclui um arquivo `requirements.txt` que lista todas as bibliotecas Python (PyTorch, Albumentations, OpenCV, etc.) que este projeto utiliza.
    * Se voc√™ decidir rodar o projeto localmente (fora do Colab), voc√™ pode criar um ambiente virtual (`venv`) e instalar tudo facilmente com um √∫nico comando:
    pip install -r requirements.txt

2.  **Credenciais do Kaggle (`kaggle.json`):**
    * Para que o download do dataset funcione no Google Colab, voc√™ **precisa** fazer o upload do seu arquivo `kaggle.json`.
    * **LOCALIZA√á√ÉO CR√çTICA:** √â essencial que voc√™ solte este arquivo no diret√≥rio raiz do Colab, **fora de qualquer outra pasta**. O script procura o arquivo no caminho exato `/content/kaggle.json`. Se ele for colocado dentro de outra pasta, o download falhar√°.

3.  **Ambiente:** Certifique-se de estar usando um ambiente com **GPU** (`Ambiente de execu√ß√£o > Alterar tipo`).

4.  **N√∫mero de √âpocas (Epochs):**
    * O *notebook* est√° configurado com `NUM_EPOCHS = 2`.
    * Isso √© intencional para permitir um **teste r√°pido** do pipeline, j√° que o `deeplabv3_resnet50` √© um modelo grande e cada √©poca de treino demora.
    * Para resultados reais e um modelo bem treinado, **aumente este valor** (ex: 10, 20 ou mais), como sugerido no coment√°rio do pr√≥prio c√≥digo.

5.  **Executar:** Rode as c√©lulas do *notebook* em ordem.
